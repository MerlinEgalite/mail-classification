{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "\n",
    "We want to proceed to a dimensionality reduction using the LDA algorithm.\n",
    "\n",
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/trainEncoded.csv', index_col=0)\n",
    "X=train.drop('label',axis=1).values\n",
    "y=train['label'].values;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the data\n",
    "\n",
    "We want to standardize the data to have a unit variance and a null mean on each column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_scaled=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA processing\n",
    "\n",
    "We need to set the proper hyperparameter for our LDA. We can choose the number of features we want to project our data on. Therefore, we will use the gridsearch function to find the best dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6710773503226334 1\n",
      "0.6710773503226334 2\n",
      "0.6710773503226334 3\n"
     ]
    }
   ],
   "source": [
    "# clf = LDA()\n",
    "# X_LDA=clf.fit_transform(X_scaled,y);\n",
    "\n",
    "# searchParams={'n_components':[2,4,6,8,10,12]}\n",
    "# lda= LDA()\n",
    "# model = GridSearchCV(lda, param_grid=searchParams,cv=4)\n",
    "# model=model.fit(X,y)\n",
    "\n",
    "# model.best_params_\n",
    "listLDA=[]\n",
    "\n",
    "for n in [1,2,3]:\n",
    "    clf=LDA(n_components=n)\n",
    "    clf.fit(X_scaled,y)\n",
    "    listLDA.append(clf)\n",
    "    print(clf.score(X_scaled,y),n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally find that a sole feature is enough for the LDA classification. However, the score is based on the classification performed by the LDA algorithm and not by the future algorithms we are prone to use. Therefore, we should save the three lda classifiers with values of n_components ranging from 1 to 3.\n",
    "\n",
    "## Saving\n",
    "\n",
    "We will not save our new datasets but only our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin=\"D:/Utilisateurs/Bastien/Documents/Cours/CentraleSupelec/Electifs/Machine Learning/Evaluations/Assignment 2/mail-classification/LDA_classifiers.txt\"\n",
    "with open('lda_classifiers.txt','wb') as fichier:\n",
    "    pickler=pk.Pickler(fichier)\n",
    "    pickler.dump(listLDA)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
